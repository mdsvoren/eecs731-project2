{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sps = pd.read_csv(\"../data/Shakespeare_data.csv\")\n",
    "print(sps.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shakespeare data is loaded into a data frame and, but still needs to be cleaned. We want to remove all of the extraneous, non-dialogue lines, which can be done by removing all lines where the row includes NaN. These occur during transitions primarily and are not relevant to our model. They happen infrequently enough otherwise that it will not skew the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = sps.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional value could be derived from the data set by looking at who speaks the most lines in each play, as this could be a proxy for pay scale when actually doing a production of a Shakespeare play. For instance, we compare King Henry IV to Prince Henry below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "isHenryIV = cleaned['Play']=='Henry IV'\n",
    "HenryIVPlay = cleaned[isHenryIV]\n",
    "isKingHenry = HenryIVPlay['Player']==\"KING HENRY IV\"\n",
    "kingHenryLines = len(HenryIVPlay[isKingHenry])\n",
    "isPrinceHenry = HenryIVPlay['Player']==\"PRINCE HENRY\"\n",
    "princeHenryLines = len(HenryIVPlay[isPrinceHenry])\n",
    "\n",
    "nums = (kingHenryLines, princeHenryLines)\n",
    "people = ('King Henry', 'Prince Henry')\n",
    "y_pos = np.arange(len(people))\n",
    "performance = 5 + 10 * np.random.rand(len(people))\n",
    "error = np.random.rand(len(people))\n",
    "\n",
    "ax.barh(y_pos, nums, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(people)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Lines')\n",
    "ax.set_title('Lines Per Actor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows just 2 of the players and the quantity of lines they have in Henry IV. This analysis could be extended to include any number of players. The specific feature engineering here is breaking down the dataset by play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will further prepare the dataset to be inputed to the classification model. We will use one-hot encoding to incorporate the strings into the model. One-hot encoding is used to ensure that the different feature attributes are not \"mixed up\" with one another. We also drop the player line here because it's not useful in one-hot encoding due to the wide variety of possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "#x_2 = x.apply(le.fit_transform)\n",
    "cat_columns = [\"Play\",\"Player\"]\n",
    "df_processed = pd.get_dummies(cleaned, prefix_sep=\"__\", columns = cat_columns)\n",
    "\n",
    "cat_dummies = [col for col in df_processed \n",
    "               if \"__\" in col \n",
    "               and col.split(\"__\")[0] in cat_columns]\n",
    "\n",
    "processed_columns = list(df_processed.columns[:])\n",
    "\n",
    "df_processed.head(5)\n",
    "df_processed.drop(columns = ['PlayerLine'], inplace=True)\n",
    "data = df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we separate X and Y data.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Xtemp = data['PlayerLinenumber']\n",
    "A = data.loc[:, ~data.columns.str.startswith('Player')]\n",
    "X = pd.merge(Xtemp, A, left_index = True, right_index = True)\n",
    "X = X.drop('ActSceneLine', axis = 1)\n",
    "Y = data.loc[:, data.columns.str.startswith('Player')]\n",
    "Y = Y.drop(['PlayerLinenumber'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use a classification model to determine the player using the other columns as features. The first step will be breaking the data up into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1, test_size = .2)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "Y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(Y_test, Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see directly above, the accuracy of our model was roughly 72%. This is strong performance, which makes me think the decision tree may be overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
